{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuT9OAeGlwjx"
      },
      "source": [
        "# NumPy Basics\n",
        "\n",
        "Welcome to your NumPy practice. This practice gives you a brief introduction to NumPy library in Python. \n",
        "\n",
        "## Objectives\n",
        "- Learn Jupyter Notebook basics.\n",
        "- Learn basic numpy operations on arrays/matrices.\n",
        "\n",
        "## Instructions\n",
        "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
        "- Write your code between the commented lines: $\\color{green}{\\textbf{\\small \\#\\#\\# START CODE HERE \\#\\#\\#}}$ and $\\color{green}{\\textbf{\\small \\#\\#\\# END CODE HERE \\#\\#\\#}}$. \n",
        "- $\\color{red}{\\textbf{Modify code out of the designated area at your own risk.}}$\n",
        "- Reference answers are provided. Be aware if your answer is different from the reference.\n",
        "\n",
        "## Exercises:\n",
        "1. $\\color{violet}{\\textbf{(15\\%) Sigmoid function with math}}$\n",
        "2. $\\color{violet}{\\textbf{(15\\%) Sigmoid function with numpy}}$\n",
        "3. $\\color{violet}{\\textbf{(15\\%) Sigmoid derivative}}$\n",
        "4. $\\color{violet}{\\textbf{(35\\%) Image array manipulation}}$\n",
        "5. $\\color{violet}{\\textbf{(20\\%) Vectorization}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIe7FyMilwj5"
      },
      "source": [
        "## 1 - NumPy Functions\n",
        "\n",
        "[NumPy](https://numpy.org/) is an open source project aiming to enable numerical computing with Python.  It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more. \n",
        "\n",
        "In this exercise you will learn how to construct customized functions using NumPy. \n",
        "\n",
        "### 1.1 - Sigmoid function ###\n",
        "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ \n",
        "is also known as the logistic function. It is usually used as an non-linear activation in neural network models.\n",
        "\n",
        "![](https://mathworld.wolfram.com/images/eps-svg/SigmoidFunction_701.svg)\n",
        "\n",
        "#### $\\color{violet}{\\textbf{Exercise 1: Sigmoid function with math}}$\n",
        "Construct a sigmoid function using Python's built-in `math` module. Hint: **`math.exp(x)`** will perform exponential operation: $e^x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w3f8uk8llwj6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def math_sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute sigmoid of x.\n",
        "\n",
        "    Arguments:\n",
        "        x: scalar\n",
        "\n",
        "    Return:\n",
        "        y: same as x\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return y\n",
        "\n",
        "y = math_sigmoid(3)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6nAbKh-lwj7"
      },
      "source": [
        "> Expected Output: \n",
        "```python\n",
        "0.9525741268224334\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX3OZTITNMbO"
      },
      "source": [
        "Actually, we rarely use `math` library in deep learning because matrices and vectors are more common, instead of a scalar. This is why numpy is more useful. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTFsqRuqlwj7"
      },
      "outputs": [],
      "source": [
        "# You'll get an error since math library cannot deal with vectors\n",
        "x = [1, 2, 3]\n",
        "math_sigmoid(x) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGaI8PJfP_XK"
      },
      "source": [
        "By using numpy, `x` could now be either a number, a vector, or a matrix. The data type of a vector, a matrix or a scalar is called the numpy **array**. If $x = [x_1, x_2, ..., x_n]$ then `np.exp(x)` will apply the exponential operation to every element of `x`. Therefore: $np.exp(x) = [e^{x_1}, e^{x_2}, ..., e^{x_n}]$. Also, $x + 3$ or $\\frac{1}{x}$ will perform elementwise operations. And the output should be a vector with the same shape as `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVCb_7wElwj8",
        "outputId": "e649364a-f8ec-41ec-8a91-df046d644acd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "print(np.exp(x))\n",
        "print(x + 3)\n",
        "print(1 / x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOswWkZ0lwj9"
      },
      "source": [
        "\n",
        "#### $\\color{violet}{\\textbf{Exercise 2: Sigmoid function with \\textit{numpy} library}}$\n",
        "Construct a sigmoid function for numpy arrays.\n",
        " \n",
        "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } \\sigma(x) = \\sigma\\begin{pmatrix}\n",
        "    x_1  \\\\\n",
        "    x_2  \\\\\n",
        "    ...  \\\\\n",
        "    x_n  \\\\\n",
        "\\end{pmatrix} = \\begin{pmatrix}\n",
        "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
        "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
        "    ...  \\\\\n",
        "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
        "\\end{pmatrix}\\tag{1} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhBPccRLlwj9"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "def numpy_sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of x\n",
        "\n",
        "    Arguments:\n",
        "        x: scalar or numpy array\n",
        "\n",
        "    Return:\n",
        "        y: same as x\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return y\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "numpy_sigmoid(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nou6SkKDlwj-"
      },
      "source": [
        "> Expected Output:\n",
        "```python\n",
        "array([0.73105858, 0.88079708, 0.95257413])\n",
        "``` \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezNagT8elwj-"
      },
      "source": [
        "### 1.2 - Sigmoid Derivative\n",
        "\n",
        "An interesting fact is the derivative of the sigmoid function can be calculated by employing itself recursively.\n",
        "$$\\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n",
        "\n",
        "#### $\\color{violet}{\\textbf{Exercise 3: Sigmoid derivative}}$\n",
        "Please use previously defined sigmoid function to construct its derivative function. \n",
        "Such function has to be compatible with Numpy arrays.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JYGfsyklwj-"
      },
      "outputs": [],
      "source": [
        "def d_sigmoid(x):\n",
        "    \"\"\"    \n",
        "    Arguments:\n",
        "        x: scalar or numpy array\n",
        "\n",
        "    Return:\n",
        "        dydx: derevative of sigmoid function with respect to x.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return dydx\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "print (f\"grad(x) = {grad_sigmoid(x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBnZAuZ-lwj-"
      },
      "source": [
        "> Expected Output: \n",
        "```python\n",
        "grad(x) = [0.19661193 0.10499359 0.04517666]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDmC5kojlwj_"
      },
      "source": [
        "## 2 - Explore NumPy Array\n",
        "\n",
        "Numpy arrays are usually used to represent object with high dimensions.\n",
        "For example, a colored image is usually represented by a 3-dimensional array with the shape of `(# horizontal pixels, # vertical pixels, # color channels)`. \n",
        "It is a stack of 3 matrices with the shape of `(# horizontal pixels, # vertical pixels)`.\n",
        "The color channels are usually ordered in the sequence of red, green, blue.\n",
        "\n",
        "![](https://eli.thegreenplace.net/images/2015/row-major-3D.png)\n",
        "\n",
        "#### $\\color{violet}{\\textbf{Exercise 4: Image array manipulation}}$\n",
        "You will load the `bearhead.png` as a NumPy array. \n",
        "Please refer to the officail [documentation](https://numpy.org/doc/stable/reference/) to complete following tasks.\n",
        "1. Find out shape of the image array.\n",
        "2. Find out dimension of the image array.\n",
        "3. Extract pixels in red channel (first color channle).\n",
        "4. Transpose pixel matrix from the red channel.\n",
        "5. Reshape the image array into a row vector. \n",
        "**Please don't hardcode the second dimension of the array as a constant.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RvtZ5nfmlwj_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image shape: (91, 100, 3)\n",
            "image dimension: 3\n",
            "red channel shape: (91, 100)\n",
            "transposed red channel shape: (100, 91)\n",
            "flattened image shape: (1, 27300)\n",
            "100th to 110th pixel values in the flattend image: [[251 252 254 253 254 255 254 255 255 254 255]]\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "image = np.asarray(PIL.Image.open('bearhead.jpg'))  # array\n",
        "\n",
        "### START CODE HERE ### (≈ 5 lines of code)\n",
        "image_shape = image.shape\n",
        "image_dim = image.ndim\n",
        "image_red = image[:,:,0]\n",
        "image_red_transpose = image_red.T\n",
        "image_flatten = image.reshape(1, -1) # reshape to a row vector\n",
        "mean_red = image.mean(axis=)\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(f\"image shape: {image_shape}\")\n",
        "print(f\"image dimension: {image_dim}\")\n",
        "print(f\"red channel shape: {image_red.shape}\")\n",
        "print(f\"transposed red channel shape: {image_red_transpose.shape}\")\n",
        "print (f\"flattened image shape: {image_flatten.shape}\")\n",
        "print (f\"100th to 110th pixel values in the flattend image: {image_flatten[:, 99:110]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LvRhmo3lwj_"
      },
      "source": [
        ">Expected Output: \n",
        "```python\n",
        "image shape: (91, 100, 3)\n",
        "image dimension: 3\n",
        "red channel shape: (91, 100)\n",
        "transposed red channel shape: (100, 91)\n",
        "flattened image shape: (1, 27300)\n",
        "100th to 110th pixel values in the flattend image: [[251 252 254 253 254 255 254 255 255 254 255]]\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qecUM8bjlwkA"
      },
      "source": [
        ">Expected Output: \n",
        "```python\n",
        "normalizeRows(x) = [[0.         0.6        0.8       ]\n",
        " [0.13736056 0.82416338 0.54944226]]\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7jK4S--lwkC"
      },
      "source": [
        "## 3. Vectorization and Matrix Operations\n",
        "\n",
        "### 2.1 NumPy optimized vector operations\n",
        "In deep learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is computationally efficient, you will use vectorized operations instead of the for/while loops. Implement the following computations of the dot/elementwise product to observe the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMz3ORColwkC",
        "outputId": "c850b47f-03ea-4f5b-ec72-ce2e80edc453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dot = [[-1.47206415e+00 -2.01058869e+01  4.19721216e+01 ... -1.51959714e+01\n",
            "  -3.66189431e+00 -1.07637166e+01]\n",
            " [-1.39202504e+01  3.79584060e+00  8.66744038e+00 ... -1.03306193e+01\n",
            "  -1.23546117e+01 -9.20454347e+00]\n",
            " [-1.39304838e+01 -2.49531017e+01  5.28262363e+00 ...  1.33543275e+01\n",
            "   1.22793547e+00 -4.07582619e+00]\n",
            " ...\n",
            " [-1.14553598e-03  9.76925062e+00 -2.41121788e+01 ...  3.18441208e+00\n",
            "   2.29356216e+01 -3.03192250e+00]\n",
            " [-8.48935459e+00  2.60933426e+01  1.59376343e+01 ... -1.53591851e+01\n",
            "   1.45932409e+01 -1.46030117e+01]\n",
            " [-1.58307687e+01  2.40655945e+01 -3.36467475e-01 ... -4.71283437e+00\n",
            "  -7.35479047e+00 -1.57770426e+01]]\n",
            "----- Computation time = 5661.232570999971 ms\n",
            "\n",
            "elementwise multiplication = [[-0.47791793  0.22277516 -0.2647101  ... -0.12580996  0.19702801\n",
            "   1.46838924]\n",
            " [-1.66405907 -0.49208664  0.44340912 ...  0.85618109 -0.05242038\n",
            "  -1.25039097]\n",
            " [-0.68492231 -0.05459413  0.1880655  ... -0.17973809 -1.53994289\n",
            "   0.03223162]\n",
            " ...\n",
            " [-0.46304039 -0.08048796 -3.67474354 ...  0.17366331  0.56299916\n",
            "  -0.04524836]\n",
            " [ 0.06168739 -4.03047113  0.00989387 ... -0.5797955   1.06473212\n",
            "  -0.07620197]\n",
            " [-0.27591294  0.06755951  0.62546616 ...  0.18494353  0.06822288\n",
            "  -1.56284019]]\n",
            "----- Computation time = 17.20787500005372 ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "np.random.seed(3321)\n",
        "\n",
        "x1 = np.random.normal(0, 1, (256, 256))\n",
        "x2 = np.random.normal(0, 1, (256, 256))\n",
        "\n",
        "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
        "dot = np.zeros((256, 256))\n",
        "tic = time.process_time()\n",
        "for i in range(256):\n",
        "    # Iterate through each column of the second matrix (B)\n",
        "    for j in range(256):\n",
        "        # Iterate through the elements of the row and column to compute the sum of products\n",
        "        for k in range(256):\n",
        "            dot[i, j] += x1[i, k] * x2[k, j]\n",
        "toc = time.process_time()\n",
        "print(f\"dot = {dot}\\n----- Computation time = {1000*(toc - tic)} ms\\n\")\n",
        "\n",
        "### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n",
        "mul = np.zeros((256, 256))\n",
        "tic = time.process_time()\n",
        "for i in range(256):\n",
        "    for j in range(256):\n",
        "        mul[i, j] = x1[i, j] * x2[i, j]\n",
        "toc = time.process_time()\n",
        "print(f\"elementwise multiplication = {mul}\\n----- Computation time = {1000*(toc - tic)} ms\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksLjxQc0nUFh"
      },
      "source": [
        "#### $\\color{violet}{\\textbf{Exercise 5: Vectorization}}$\n",
        "Use NumPy and vectorized operations to \n",
        "1. Implement dot product between `x1` and `x2`.\n",
        "2. Implement elementwise multiplication between `x1` and `x2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8DZAUeVlwkD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy dot = None\n",
            "----- Computation time = 0.06318800001281488 ms\n",
            "\n",
            "numpy elementwise multiplication = None\n",
            "----- Computation time = 0.04713900000297144 ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### VECTORIZED DOT PRODUCT OF VECTORS ###\n",
        "tic = time.process_time()\n",
        "### START CODE HERE ### (≈ 1 line)\n",
        "np_dot = None\n",
        "### END CODE HERE ###\n",
        "toc = time.process_time()\n",
        "print(f\"numpy dot = {np_dot}\\n----- Computation time = {1000*(toc - tic)} ms\\n\")  # 10%\n",
        "\n",
        "\n",
        "### VECTORIZED ELEMENTWISE MULTIPLICATION ###\n",
        "tic = time.process_time()\n",
        "### START CODE HERE ### (≈ 1 line)\n",
        "np_mul = None\n",
        "### END CODE HERE ###\n",
        "toc = time.process_time()\n",
        "print(f\"numpy elementwise multiplication = {np_mul}\\n----- Computation time = {1000*(toc - tic)} ms\\n\")  # 10%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Pq9rOGlwkD"
      },
      "source": [
        "As you may have noticed, the vectorized implementation is much cleaner and more efficient. For bigger vectors/matrices, the differences in running time become even bigger. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3PUrGLMlwkE"
      },
      "source": [
        "# Congratulations! \n",
        "\n",
        "You have finished this assignment!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "numpy_basics.ipynb",
      "provenance": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XHpfv",
      "launcher_item_id": "Zh0CU"
    },
    "kernelspec": {
      "display_name": "3321",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
